# 第8章：遗憾界

*Edit: Hao ZHAN*

*Update: 09/23/2020*

---

本章的内容围绕学习理论中的遗憾（regret）概念展开（有的教材里也翻译为“悔” ）。通常，我们使用超额风险（excess risk）来评估批量学习的分类器性能，而用遗憾来评估在线学习的分类器性能。二者的不同在于，前者衡量的是整个学习过程结束后所得到的分类器性能，可以理解为学习算法**最终输出的模型**与假设空间内**最优模型**的风险之差；而后者衡量的是算法运行过程中，所产生的**模型**与假设空间内**最优模型**的损失之差的**和**。

本章内容较为清晰，需要补充的内容较少，我们只选择对其中的部分概念进行梳理。



## 1. 【概念补充】超额风险与遗憾的区别

8.1介绍了遗憾这一评估指标的基本概念，我们在此基础上梳理一下其与超额风险这一评估指标的区别。

超额风险这一评估指标被定义为，
$$
ER = \mathbb{E}_{(x,y)\sim D[l(w_{T+1},(x,y))]} - min_{w \in W} \mathbb{E}_{(x,y)\sim D[l(w,(x,y))]}
$$
其中，$ER$ 指的是excess risk，等式右边的前半部分 $\mathbb{E}_{(x,y)\sim D[l(w_{T+1},(x,y))]}$ 指的是模型 $w_{T+1}$ 的风险，等式右边的后半部分 $min_{w \in W} \mathbb{E}_{(x,y)\sim D[l(w,(x,y))]}$ 指的是假设空间内的最优模型的风险。值得注意的是，这里的评估是在整个数据集上进行的，也正是因为如此，我们必须要引入期望的操作。

而遗憾这一评估指标，被定义为，
$$
regret = \sum^{T}_{t=1}f_t(w_t)-min_{w\in W}\sum^{T}_{t=1}f_t(w)
$$
其中，$f_t(w_t)$ 指的是，
$$
\sum^{T}_{t=1}l(w_t,(x_t,y_t)) - min_{w \in W}\sum^{T}_{t=1}l(w,(x_t,y_t))
$$
由于$w_t$的计算过程与样本$(x_t,y_t)$ 无关，而是与$(x_1,y_1)...(x_{t-1},y_{t-1})$ 有关，因此可以直接使用 $l(w,(x_t,y_t))$ 来衡量性能。

由此，我们可以总结出二者之间的两个主要区别。一是超额风险引入了**期望**而遗憾没有；二是超额风险计算是一次性在所有数据上进行的计算，而遗憾是对多次损失的一个**求和**。同时，由于在线学习不依赖于任何分布假设，因此其适用于一系列样本并非 i.i.d ，或者才样子固定分布的情形。

