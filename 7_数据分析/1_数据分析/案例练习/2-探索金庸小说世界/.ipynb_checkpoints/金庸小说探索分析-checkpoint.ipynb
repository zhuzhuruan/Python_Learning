{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd6c9af",
   "metadata": {},
   "source": [
    "# 一、高频分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29bec5a",
   "metadata": {},
   "source": [
    "定义加载小说的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd188c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_novel(novel):\n",
    "    with open(f'./file/novels/{novel}.txt', 'rt', encoding='utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a46e37",
   "metadata": {},
   "source": [
    "# 二、主角分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71cdf4",
   "metadata": {},
   "source": [
    "加载人物数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./file/data/names.txt', 'rt', encoding='utf-8') as f:\n",
    "    data = [line.rstrip() for line in f]\n",
    "    novels = data[::2]\n",
    "    names = data[1::2]\n",
    "    novel_names = {k: v.split() for k,v in zip(novels, names)}\n",
    "    del novels, names, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a6a21",
   "metadata": {},
   "source": [
    "可以预览一下《天龙八部》中的人物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da8cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\",\".join(novel_names['书剑恩仇录'][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e622c85",
   "metadata": {},
   "source": [
    "下面我们寻找一下每部小说的主角，统计每个人物的出场次数，显然次数越多主角光环越强，下面我们看看每部小说，出现次数最多的前十个人物："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e00e818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def find_main_characters(novel, num=10, content=None):\n",
    "    if content is None:\n",
    "        content = load_novel(novel)\n",
    "    count = Counter()\n",
    "    for name in novel_names[novel]:\n",
    "        count[name] = content.count(name)\n",
    "    return count.most_common(num)\n",
    "\n",
    "for novel in novel_names:\n",
    "    print(novel, find_main_characters(novel, num=5, content=None))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fe278e",
   "metadata": {},
   "source": [
    "上述结果用文本展示了每部小说的前5个主角，但是不够直观，下面用pyecharts的树图展示一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92becd19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import TreeMap\n",
    "\n",
    "data = []\n",
    "for novel in novel_names:\n",
    "    tmp = []\n",
    "    data.append({\"name\": novel, \"children\": tmp})\n",
    "    for name, count in find_main_characters(novel, 5):\n",
    "        tmp.append({\"name\": name, \"value\": count})\n",
    "c = (\n",
    "    TreeMap()\n",
    "    .add(\"\", data, levels=[\n",
    "        opts.TreeMapLevelsOpts(),\n",
    "        opts.TreeMapLevelsOpts(\n",
    "            color_saturation=[0.4, 0.6],\n",
    "            treemap_itemstyle_opts=opts.TreeMapItemStyleOpts(\n",
    "                border_color_saturation=0.7, gap_width=5, border_width=10\n",
    "            ),\n",
    "            upper_label_opts=opts.LabelOpts(\n",
    "                is_show=True, position='insideTopLeft', vertical_align='top'\n",
    "            )\n",
    "        ),\n",
    "    ])\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"金庸小说主角\"))\n",
    ")\n",
    "c.render_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323634b2",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 三、武功分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2026eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./file/data/kungfu.txt', 'rt', encoding='utf-8') as f:\n",
    "    data = [line.rstrip() for line in f]\n",
    "    novels = data[::2]\n",
    "    kungfu = data[1::2]\n",
    "    novel_kungfu = {k: v.split() for k,v in zip(novels, kungfu) if k!= '未知'}\n",
    "    del novels, kungfu, data\n",
    "    \n",
    "def find_main_kungfus(novel, num=10, content=None):\n",
    "    if content is None:\n",
    "        content = load_novel(novel)\n",
    "    count = Counter()\n",
    "    for kungfu in novel_kungfu[novel]:\n",
    "        count[kungfu] = content.count(kungfu)\n",
    "    return count.most_common(num)\n",
    "\n",
    "data = []\n",
    "for novel in novel_kungfu:\n",
    "    tmp = []\n",
    "    data.append({\"name\": novel, \"children\": tmp})\n",
    "    for name, count in find_main_kungfus(novel, 5):\n",
    "        tmp.append({\"name\": name, \"value\": count})\n",
    "c = (\n",
    "    TreeMap()\n",
    "    .add(\"\", data, levels=[\n",
    "        opts.TreeMapLevelsOpts(),\n",
    "        opts.TreeMapLevelsOpts(\n",
    "            color_saturation=[0.4, 0.6],\n",
    "            treemap_itemstyle_opts=opts.TreeMapItemStyleOpts(\n",
    "                border_color_saturation=0.7, gap_width=5, border_width=10\n",
    "            ),\n",
    "            upper_label_opts=opts.LabelOpts(\n",
    "                is_show=True, position='insideTopLeft', vertical_align='top'\n",
    "            )\n",
    "        ),\n",
    "    ])\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"金庸小说主角\"))\n",
    ")\n",
    "c.render_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f47d1",
   "metadata": {},
   "source": [
    "# 四、门派分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19217b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./file/data/bangs.txt', encoding=\"utf-8\") as f:\n",
    "    data = [line.rstrip() for line in f]\n",
    "novels = data[::2]\n",
    "bangs = data[1::2]\n",
    "novel_bangs = {k: v.split() for k, v in zip(novels, bangs) if k != \"未知\"}\n",
    "del novels, bangs, data\n",
    "\n",
    "\n",
    "def find_main_bangs(novel, num=10, content=None):\n",
    "    if content is None:\n",
    "        content = load_novel(novel)\n",
    "    count = Counter()\n",
    "    for name in novel_bangs[novel]:\n",
    "        count[name] = content.count(name)\n",
    "    return count.most_common(num)\n",
    "\n",
    "data = []\n",
    "for novel in novel_bangs:\n",
    "    tmp = []\n",
    "    data.append({\"name\": novel, \"children\": tmp})\n",
    "    for name, count in find_main_bangs(novel, 5):\n",
    "        tmp.append({\"name\": name, \"value\": count})\n",
    "c = (\n",
    "    TreeMap()\n",
    "    .add(\"\", data, levels=[\n",
    "        opts.TreeMapLevelsOpts(),\n",
    "        opts.TreeMapLevelsOpts(\n",
    "            color_saturation=[0.3, 0.6],\n",
    "            treemap_itemstyle_opts=opts.TreeMapItemStyleOpts(\n",
    "                border_color_saturation=0.7, gap_width=5, border_width=10\n",
    "            ),\n",
    "            upper_label_opts=opts.LabelOpts(\n",
    "                is_show=True, position='insideTopLeft', vertical_align='top'\n",
    "            )\n",
    "        ),\n",
    "    ])\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"金庸高频门派\"))\n",
    ")\n",
    "c.render_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07fc7a5",
   "metadata": {},
   "source": [
    "下面编写一个函数，输入一部小说名，可以输出其最高频的主角、武功和门派："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Bar\n",
    "\n",
    "def show_top10(novel):\n",
    "    content = load_novel(novel)\n",
    "    charecters = find_main_characters(novel, 10, content)[::-1]\n",
    "    k, v = map(list, zip(*charecters))\n",
    "    c = (\n",
    "        Bar(init_opts=opts.InitOpts(\"720px\", \"320px\"))\n",
    "        .add_xaxis(k)\n",
    "        .add_yaxis(\"\", v)\n",
    "        .reversal_axis()\n",
    "        .set_series_opts(label_opts=opts.LabelOpts(position=\"right\"))\n",
    "        .set_global_opts(title_opts=opts.TitleOpts(title=f\"{novel}主角\"))\n",
    "    )\n",
    "    display(c.render_notebook())\n",
    "    kungfus = find_main_kungfus(novel, 10, content)[::-1]\n",
    "    k, v = map(list, zip(*kungfus))\n",
    "    c = (\n",
    "        Bar(init_opts=opts.InitOpts(\"720px\", \"320px\"))\n",
    "        .add_xaxis(k)\n",
    "        .add_yaxis(\"\", v)\n",
    "        .reversal_axis()\n",
    "        .set_series_opts(label_opts=opts.LabelOpts(position=\"right\"))\n",
    "        .set_global_opts(title_opts=opts.TitleOpts(title=f\"{novel}功夫\"))\n",
    "    )\n",
    "    display(c.render_notebook())\n",
    "    bangs = find_main_bangs(novel, 10, content)[::-1]\n",
    "    k, v = map(list, zip(*bangs))\n",
    "    c = (\n",
    "        Bar(init_opts=opts.InitOpts(\"720px\", \"320px\"))\n",
    "        .add_xaxis(k)\n",
    "        .add_yaxis(\"\", v)\n",
    "        .reversal_axis()\n",
    "        .set_series_opts(label_opts=opts.LabelOpts(position=\"right\"))\n",
    "        .set_global_opts(title_opts=opts.TitleOpts(title=f\"{novel}门派\"))\n",
    "    )\n",
    "    display(c.render_notebook())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c249bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top10(\"天龙八部\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e63e4",
   "metadata": {},
   "source": [
    "# 五、词云图分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ddf9b1",
   "metadata": {},
   "source": [
    "可以先添加所有的人物、武功和门派作为自定义词汇："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579dbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "for novel, names in novel_names.items():\n",
    "    for name in names:\n",
    "        jieba.add_word(name)\n",
    "        \n",
    "for novel, kungfus in novel_kungfu.items():\n",
    "    for kungfu in kungfus:\n",
    "        jieba.add_word(kungfu)\n",
    "\n",
    "for novel, bangs in novel_bangs.items():\n",
    "    for bang in bangs:\n",
    "        jieba.add_word(bang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a22b4",
   "metadata": {},
   "source": [
    "## 文章整体词云查看"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aadbf4",
   "metadata": {},
   "source": [
    "这里我们仅提取词长度不小于4的成语、俗语和短语进行分析，以天龙八部这部小说为例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ace54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import stylecloud\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "text = re.sub(\"[^一-龟]+\", \" \", load_novel(\"天龙八部\"))\n",
    "words = [word for word in jieba.cut(text) if len(word) >=4]\n",
    "stylecloud.gen_stylecloud(\" \".join(words),\n",
    "                          collocations=False,\n",
    "                          font_path=r'C:\\Windows\\Fonts\\msyhbd.ttc',\n",
    "                          icon_name='fas fa-square',\n",
    "                          output_name='tmp.png')\n",
    "Image(filename='./file/tmp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07384aa",
   "metadata": {},
   "source": [
    "## 主角相关剧情词云"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b8b3a",
   "metadata": {},
   "source": [
    "我们知道《神雕侠侣》这部小说最重要的主角是杨过和小龙女，我们可能会对于杨过和小龙女之间所发生的故事很感兴趣。如果通过程序快速了解呢？\n",
    "\n",
    "我们考虑把《神雕侠侣》这部小说每一段中出现杨过及小龙女的段落进行jieba分词并制作词云。\n",
    "\n",
    "同样我们只看4个字以上的词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493329d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in load_novel(\"神雕侠侣\").splitlines():\n",
    "    if \"杨过\" in line and \"小龙女\" in line:\n",
    "        line = re.sub(\"[^一-龟]+\", \" \", line)\n",
    "        data.extend(word for word in jieba.cut(line) if len(word) >= 4)\n",
    "stylecloud.gen_stylecloud(\" \".join(data),\n",
    "                          collocations=False,\n",
    "                          font_path=r'C:\\Windows\\Fonts\\msyhbd.ttc',\n",
    "                          icon_name='fas fa-square',\n",
    "                          output_name='tmp.png')\n",
    "Image(filename='./file/tmp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812b07b",
   "metadata": {},
   "source": [
    "# 六、人物关系分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dece313",
   "metadata": {},
   "source": [
    "金庸小说15部小说中预计出现了1400个以上的角色，下面我们将遍历小说的每一段，在一段中出现的任意两个角色，都计数1。最终我们取出现频次最高的前200个关系对进行可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e43c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Graph\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "count = Counter()\n",
    "for novel in novel_names:\n",
    "    names = novel_names[novel]\n",
    "    re_rule = f\"({'|'.join(names)})\"\n",
    "    for line in load_novel(novel).splitlines():\n",
    "        names = list(set(re.findall(re_rule, line)))\n",
    "        if names and len(names) >= 2:\n",
    "            names.sort()\n",
    "            for s, t in itertools.combinations(names, 2):\n",
    "                count[(s, t)] += 1\n",
    "count = count.most_common(200)\n",
    "node_count, nodes, links = Counter(), [], []\n",
    "for (n1, n2), v in count:\n",
    "    node_count[n1] += 1\n",
    "    node_count[n2] += 1\n",
    "    links.append({\"source\": n1, \"target\": n2})\n",
    "for node, count in node_count.items():\n",
    "    nodes.append({\"name\": node, \"symbolSize\": int(math.log(count)*5)+5})\n",
    "c = (\n",
    "    Graph(init_opts=opts.InitOpts(\"1280px\",\"960px\"))\n",
    "    .add(\"\", nodes, links, repulsion=30)\n",
    ")\n",
    "c.render(\"./file/tmp.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2daab",
   "metadata": {},
   "source": [
    "# 七、Word2Vec分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c94eac",
   "metadata": {},
   "source": [
    "Word2Vec是一款将词表征为实数值向量的高效工具，接下来，我们将使用它来处理这些小说。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35513bb6",
   "metadata": {},
   "source": [
    "首先我要将所有小说的段落分词后添加到组织到一起（前面的程序可以重启）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61f8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def load_novel(novel):\n",
    "    with open(f'./file/novels/{novel}.txt', 'rt', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "    \n",
    "with open('./file/data/names.txt', 'rt', encoding='utf-8') as f:\n",
    "    data = f.read().splitlines()\n",
    "    novels = data[::2]\n",
    "    names = []\n",
    "    for line in data[1::2]:\n",
    "        names.extend(line.split())\n",
    "        \n",
    "with open('./file/data/kungfu.txt', encoding=\"utf-8\") as f:\n",
    "    data = f.read().splitlines()\n",
    "    kungfus = []\n",
    "    for line in data[1::2]:\n",
    "        kungfus.extend(line.split())\n",
    "\n",
    "with open('./file/data/bangs.txt', encoding=\"utf-8\") as f:\n",
    "    data = f.read().splitlines()\n",
    "    bangs = []\n",
    "    for line in data[1::2]:\n",
    "        bangs.extend(line.split())\n",
    "        \n",
    "for name in names:\n",
    "    jieba.add_word(name)\n",
    "for kungfu in kungfus:\n",
    "    jieba.add_word(kungfu)\n",
    "for bang in bangs:\n",
    "    jieba.add_word(bang)\n",
    "    \n",
    "# 去重\n",
    "names = list(set(names))\n",
    "kungfus = list(set(kungfus))\n",
    "bangs = list(set(bangs))\n",
    "\n",
    "sentences = []\n",
    "for novel in novels:\n",
    "    print(f\"处理：{novel}\")\n",
    "    for line in load_novel(novel).splitlines():\n",
    "        sentences.append(jieba.lcut(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4d222",
   "metadata": {},
   "source": [
    "接下面我们使用Word2Vec训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ec9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dadb81",
   "metadata": {},
   "source": [
    "模型训练耗时15秒，若训练耗时较长可以把训练好的模型存到本地："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91acc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./file/louis_cha.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e98299b",
   "metadata": {},
   "source": [
    "以后可以直接从本地磁盘读取模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(\"./file/louis_cha.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb5dd20",
   "metadata": {},
   "source": [
    "有了模型，我们可以进行一些简单而有趣的测试。\n",
    "\n",
    "**注意：每次生成的模型有一定随机性，后续结果根据生成的模型而变化，并非完全一致。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b82b15",
   "metadata": {},
   "source": [
    "## 相似角色、门派和武功"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d482aa",
   "metadata": {},
   "source": [
    "首先看与乔(萧)峰相似的角色："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea358b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[\"乔峰\", \"萧峰\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd6ad6",
   "metadata": {},
   "source": [
    "除了角色，我们还可以看看门派："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89abbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[\"丐帮\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a470437e",
   "metadata": {},
   "source": [
    "还可以看看与降龙十八掌相似的武功秘籍："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d7ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[\"降龙十八掌\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9b5290",
   "metadata": {},
   "source": [
    "在 Word2Vec 的模型里，有过“中国-北京=法国-巴黎”的例子，我们看看\"段誉\"和\"段公子\"类似于乔峰和什么的关系呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd9a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relationship(a, b, c):\n",
    "    d, _ = model.wv.most_similar(positive=[b, c], negative=[a])[0]\n",
    "    print(f\"{a}-{b} 犹如 {c}-{d}\")\n",
    "\n",
    "\n",
    "find_relationship(\"段誉\", \"段公子\", \"乔峰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9d0ea",
   "metadata": {},
   "source": [
    "# 八、聚类分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c9c59",
   "metadata": {},
   "source": [
    "## 人物聚类分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930a56e",
   "metadata": {},
   "source": [
    "之前我们使用 Word2Vec 将每个词映射到了一个向量空间，因此，我们可以利用这个向量表示的空间，对这些词进行聚类分析。\n",
    "\n",
    "首先取出所有角色对应的向量空间："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_names = []\n",
    "word_vectors = []\n",
    "for name in names:            \n",
    "    if name in model.wv:\n",
    "        all_names.append(name)\n",
    "        word_vectors.append(model.wv[name])\n",
    "all_names = np.array(all_names)\n",
    "word_vectors = np.vstack(word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ad056",
   "metadata": {},
   "source": [
    "聚类算法有很多，这里我们使用基本的Kmeans算法进行聚类，如果只分成3类，那么很明显地可以将众人分成主角，配角，跑龙套的三类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "N = 3\n",
    "labels = KMeans(N).fit(word_vectors).labels_\n",
    "df = pd.DataFrame({\"name\": all_names, \"label\": labels})\n",
    "for label, names in df.groupby(\"label\").name:\n",
    "    print(f\"类别{label}共{len(names)}个角色，前100个角色有：\\n{','.join(names[:100])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ba2ba",
   "metadata": {},
   "source": [
    "我们可以根据每个类别的角色数量的相对大小，判断该类别的角色是属于主角，配角还是跑龙套。\n",
    "\n",
    "下面我们过滤掉众龙套角色之后，重新聚合成四类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.Series(labels).mode().iat[0]\n",
    "remain_names = all_names[labels != c]\n",
    "remain_vectors = word_vectors[labels != c]\n",
    "remain_label = KMeans(4).fit(remain_vectors).labels_\n",
    "df = pd.DataFrame({\"name\": remain_names, \"label\": remain_label})\n",
    "for label, names in df.groupby(\"label\").name:\n",
    "    print(f\"类别{label}共{len(names)}个角色，前100个角色有：\\n{','.join(names[:100])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1b2f5",
   "metadata": {},
   "source": [
    "每次运行结果都不一样，大家可以调整类别数量继续测试。从结果可以看到，反派更倾向于被聚合到一起，非正常姓名的人物更倾向于被聚合在一起，主角更倾向于被聚合在一起。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb532ae3",
   "metadata": {},
   "source": [
    "##  人物层级聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddb9056",
   "metadata": {},
   "source": [
    "现在我们采用层级聚类的方式，查看人物间的层次关系，这里同样龙套角色不再参与聚类。\n",
    "\n",
    "层级聚类调用 scipy.cluster.hierarchy 中层级聚类的包，在此之前先解决matplotlib中文乱码问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7383dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bab4b2",
   "metadata": {},
   "source": [
    "接下来调用代码为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c68bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "y = sch.linkage(remain_vectors, method=\"ward\")\n",
    "_, ax = plt.subplots(figsize=(10, 80))\n",
    "z = sch.dendrogram(y, orientation='right')\n",
    "idx = z['leaves']\n",
    "ax.set_xticks([])\n",
    "ax.set_yticklabels(remain_names[idx], fontdict={'fontsize': 12})\n",
    "ax.set_frame_on(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5506b2",
   "metadata": {},
   "source": [
    "## 武功层级聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0d77f",
   "metadata": {},
   "source": [
    "对各种武功作与人物层次聚类相同的操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = []\n",
    "word_vectors = []\n",
    "for name in kungfus:\n",
    "    if name in model.wv:\n",
    "        all_names.append(name)\n",
    "        word_vectors.append(model.wv[name])\n",
    "all_names = np.array(all_names)\n",
    "word_vectors = np.vstack(word_vectors)\n",
    "\n",
    "Y = sch.linkage(word_vectors, method=\"ward\")\n",
    "\n",
    "_, ax = plt.subplots(figsize=(10, 40))\n",
    "Z = sch.dendrogram(Y, orientation='right')\n",
    "idx = Z['leaves']\n",
    "ax.set_xticks([])\n",
    "ax.set_yticklabels(all_names[idx], fontdict={'fontsize': 12})\n",
    "ax.set_frame_on(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80471712",
   "metadata": {},
   "source": [
    "## 门派层次聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d98947",
   "metadata": {},
   "source": [
    "最后我们对门派进行层次聚类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = []\n",
    "word_vectors = []\n",
    "for name in bangs:\n",
    "    if name in model.wv:\n",
    "        all_names.append(name)\n",
    "        word_vectors.append(model.wv[name])\n",
    "all_names = np.array(all_names)\n",
    "word_vectors = np.vstack(word_vectors)\n",
    "\n",
    "Y = sch.linkage(word_vectors, method=\"ward\")\n",
    "\n",
    "_, ax = plt.subplots(figsize=(10, 25))\n",
    "Z = sch.dendrogram(Y, orientation='right')\n",
    "idx = Z['leaves']\n",
    "ax.set_xticks([])\n",
    "ax.set_yticklabels(all_names[idx], fontdict={'fontsize': 12})\n",
    "ax.set_frame_on(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
