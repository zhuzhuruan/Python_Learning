{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8da91b",
   "metadata": {},
   "source": [
    "# Apache Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245afa99",
   "metadata": {},
   "source": [
    "# 1 什么是Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058c08c",
   "metadata": {},
   "source": [
    "- Apache Hive是一款建立在Hadoop之上的开源<font color=#FF2121>**数据仓库**</font>系统，可以将存储在Hadoop文件中的<font color=#E36C07>结构化、半结构化数据文件映射为一张数据库表</font>，基于表提供了一种类似SQL的查询模型，称为<font color=#E36C07>Hive查询语言（HQL）</font>，用于访问和分析存储在Hadoop文件的大型数据集。\n",
    "- Hive核心是将<font color=#FF2121>**HQL转换为MapReduce程序**</font>，然后将程序提交到Hadoop群集执行。\n",
    "- Hive由Facebook实现并开源。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a726366",
   "metadata": {},
   "source": [
    "# 2 为什么使用Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab218125",
   "metadata": {},
   "source": [
    "- 使用Hadoop MapReduce直接处理数据所面临的的问题\n",
    "    - 人员学习成本太高、需要掌握Java语言\n",
    "    - MapReduce实现复杂查询逻辑开发难度太大\n",
    "- 使用Hive处理数据的好处\n",
    "    - 操作接口采用类似SQL语法，提供快速开发的能力\n",
    "    - 避免直接写MapReduce，减少开发人员的学习成本\n",
    "    - 支持自定义函数，功能扩展很方便\n",
    "    - 背靠Hadoop，擅长存储分析海量数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53cdf33",
   "metadata": {},
   "source": [
    "# 3 Hive和Hadoop关系"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4d81c",
   "metadata": {},
   "source": [
    "- 从功能来说，数据仓库软件，至少需要具备下述两种能力\n",
    "    - 存储数据的能力\n",
    "    - 分析数据的能力\n",
    "- Apache Hive作为一款大数据时代的数据仓库软件，当然也具备上述两种能力。只不过Hive并不是自己实现了上述两种能力，而是借助Hadoop\n",
    "    -<font color=#FF2121>**Hive利用HDFS存储数据，利用MapReduce查询分析数据。**</font>\n",
    "- 这样突然发现Hive没啥用，不过是套壳Hadoop罢了。其实不然，Hive最大的魅力在于<font color=#E36C07>用户专与编写HQL，Hive帮您转换为MapReduce程序完成对数据的分析</font>。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07713d9e",
   "metadata": {},
   "source": [
    "# 案例：如何模拟实现Apache Hive的功能\n",
    "<br>\n",
    "如果让您设计Hive这款软件，要求能够实现<font color=#E36C07>用户编写sql语句，Hive自动将sql转换为MapReduce程序，处理位于HDFS上的结构化数据</font>。如何实现？\n",
    "<br>\n",
    "在HDFS文件系统上有一个文件，路径为/data/china_user.txt,其内容如下：\n",
    "<br>\n",
    "1，张三，18，北京<br>\n",
    "2，李四，25，上海<br>\n",
    "3，Allen，30，上海<br>\n",
    "4，王五，15，南京<br>\n",
    "5，James，45，杭州<br>\n",
    "6，Tony，26，北京<br>\n",
    "需求：统计来自于上海年龄大于25岁的用户有多少个？\n",
    "\n",
    "## 场景目的\n",
    "- **重点理解下面两点**：\n",
    "    - Hive能将数据文件映射成为一张表，这个<font color=#FF2121>**映射**</font>是指什么？\n",
    "        - <font color=#66CCFF>**文件和表之间的对应关系**</font>\n",
    "    - Hive软件本身到底承担了什么<font color=#FF2121>**功能职责**</font>？\n",
    "        - <font color=#66CCFF>**SQL语法解析编译成为MapReduce**</font>\n",
    "- **映射信息记录**\n",
    "    - <font color=#FF2121>**映射**</font>在数学上称之为一种<font color=#FF2121>**对应关系**</font>，比如y=x+1，对于每一个x值都有与之对应的y值。\n",
    "    - 在Hive中能够写sql处理的前提是针对表，而不是针对文件，因此需要将<font color=#FF2121>**文件和表之间的对应关系**</font>描述记录清楚。映射信息专业的叫法称之为<font color=#E36C07>元数据信息</font>（元数据是指用来描述数据的数据metadata）。\n",
    "    - 具体来看，要记录的元数据信息包括：\n",
    "        - 表对应着哪个文件（位置信息）\n",
    "        - 表的列对应着文件哪一个字段（顺序信息）\n",
    "        - 文件字段之间的分隔符是什么\n",
    "         \n",
    "<br>\n",
    "Hadoop HDFS → hdfs://data/china_user.txt → \n",
    "<br> \n",
    "\n",
    "|**id** |  **name**   | **age**  | **city** |\n",
    "|  :----:  |  :----:  | :----:  |:----:  |\n",
    "| 1 | 张三  | 18 | 北京 | \n",
    "| 2 | 李四 | 25  | 上海 | \n",
    "| 3 | Allen  | 30 | 上海 |  \n",
    "| 4 | 王五  | 15 | 南京 |\n",
    "| 5 | James  | 45 | 杭州 |\n",
    "| 4 | Tony  | 26 | 北京 |\n",
    "\n",
    "- **SQL语法解析、编译**\n",
    "    - 用户写完sql之后，hive需要针对sql进行语法校验，并且根据记录的元数据信息解读sql背后的含义，制定执行计划。并且把执行计划转换为MapReduce程序来执行，把执行结果封装返回给用户。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12af89e",
   "metadata": {},
   "source": [
    "# 4 Hive组件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9c0dcd",
   "metadata": {},
   "source": [
    "- <font color=#FF2121>**用户接口**</font>\n",
    "    - 包括 CLI、JDBC/ODBC、WebGUI。其中，CLI(command line interface)为shell命令行；Hive中的Thrift服务器允许外部客户端通过网络与Hive进行交互，类似于JDBC或ODBC协议。WebGUI是通过浏览器访问Hive。\n",
    "- <font color=#FF2121>**元数据存储**</font>\n",
    "    - 通常是存储在关系型数据库如mysql/derby中。Hive中的元数据包括表的名字、表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。\n",
    "- <font color=#FF2121>**Driver驱动程序，包括语法解析器、计划编译器、优化器、执行器**</font>\n",
    "    - 完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后有执行引擎调用执行。\n",
    "- <font color=#FF2121>**执行引擎**</font>\n",
    "    - Hive本身并不直接处理数据文件。而是通过执行引擎处理。当下Hive支持MapReduce、Tez、Spark3中引擎。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bca4b07",
   "metadata": {},
   "source": [
    "|**JDBC/ODBC** |  **Hive Driver驱动程序** |  |  |  |\n",
    "|  :----:  |  :----:  | :----:  |:----:  |:----:  |\n",
    "| command-line interface | Parser解析器  |  |  | \n",
    "| Hive Thrift Server | Planner任务计划 |   |  | \n",
    "| Hive Web Interface | Execution执行器  | MapReduce<br>Tez<br>Spark | Hadoop YARN |  \n",
    "|  | Optimizer优化器  |  |  |\n",
    "|  | MSClient  |  | Metastore元数据存储 | RDBMS | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fbc595",
   "metadata": {},
   "source": [
    "# 5 Apache Hive数据模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c19f3",
   "metadata": {},
   "source": [
    "## 5.1 Data Model概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef351d02",
   "metadata": {},
   "source": [
    "- 数据模型：用来描述数据、组织数据和对数据进行操作，是对现实世界数据特征的描述。\n",
    "- Hive的数据模型<font color=#E36C07>类似于RDBMS库表结构</font>，此外<font color=#E36C07>还有自己特有</font>模型。\n",
    "- Hive中的数据可以在粒度级别上分为三类：\n",
    "    - Table 表\n",
    "    - Partition 分区\n",
    "    - Bucket 桶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e39f0ed",
   "metadata": {},
   "source": [
    "## 5.2 Databases数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab8d81",
   "metadata": {},
   "source": [
    "- Hive作为一个数据仓库，在结构上积极向传统数据库看齐，也分数据库（Schema）,每个数据库下面有各自的表组成。<font color=#E36C07>默认数据库default</font>。\n",
    "- Hive的数据都是<font color=#FF2121>**存储在HDFS上**</font>的，默认有一个根目录，在Hive-site.xml中，由参数hive.metastore.warehouse.dir指定。默认值为<font color=#E36C07>/userhive/warehouset</font>。\n",
    "- 因此，hive中的数据库在HDFS上的存储路径为：${hive.metastore.warehouse.dir}databasename.db\n",
    "- 比如，名为itcast的数据库存储路径为：/user/hive/warehouse/itcast.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a650a",
   "metadata": {},
   "source": [
    "## 5.3 Tables表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b7d8f",
   "metadata": {},
   "source": [
    "- Hive表与关系数据库中的表相同。Hive中的所对应的数据通常是存储在HDFS中，而表相关的元数据是存储在RDBMS中。\n",
    "- Hive中的表的数据在HDFS上的存储路径为：${hive.metastore.warehouse.dir}databasename.db/tablename\n",
    "- 比如，itcast的数据库下t_user表存储路径为：/user/hive/warehouse/itcast.db/t_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f055b0",
   "metadata": {},
   "source": [
    "## 5.4 Partition分区"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b75f2f",
   "metadata": {},
   "source": [
    "- Partition分区是hive的一种优化手段表。分区是指<font color=\"FF2121\">**根据分区列（例如“日期day”）的值将表划分为不同分区**</font>。这样可以更快地对指定分区数据进行查询。\n",
    "- 分区在存储层面上的表现是：table表目录下以子文件夹形式存在。\n",
    "- <font color=\"FF2121\">一个文件夹表示一个分区</font>。子文件命名标准：分区列=分区值\n",
    "- Hive还支持分区下继续创建分区，所谓的多重分区。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1036bad",
   "metadata": {},
   "source": [
    "## 5.5 Buckets分桶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07401f6b",
   "metadata": {},
   "source": [
    "- Buckets分桶表是hive的一种优化手段表。分桶是指<font color=\"FF2121\">**根据表中字段（例如“编号ID”）的值，经过hash计算规则将数据文件划分成指定的若干个小文件**</font>。\n",
    "- 分桶规则：hashfunc（字段）% 桶个数，余数相同的分到同一个文件。\n",
    "- 分桶的好处是可以<font color=#E36C07>优化join查询和方便抽样查询</font>。\n",
    "- Buckets分通表在HDFS中表现为<font color=#E36C07>同一个表目录下数据根据hash散列之后变成多个文件</font>。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7d31d",
   "metadata": {},
   "source": [
    "# 6 Hive和MySQL对比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e73b3e",
   "metadata": {},
   "source": [
    "- Hive虽然具有RDBMS数据库的外表，包括数据模型、SQL语法都十分相似，但应用场景却完全不同。\n",
    "- <font color=\"FF2121\">**Hive只适合用来做海量数据的离线分析。Hive的定位是数据仓库，面向分析的OLAP系统**</font>。\n",
    "- 因此时刻告诉自己，<font color=\"FF2121\">**Hive不是大型数据库，也不是要取代MySQL承担业务数据处理**</font>。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc5fd8",
   "metadata": {},
   "source": [
    "| |  **Apache Hive**   | **Mysql**  |\n",
    "|  :----:  |  :----:  | :----:  |\n",
    "| **定位** | 数据仓库  | 数据库 |\n",
    "| **使用场景** | 离线数据分析 | 业务数据事务处理 | \n",
    "| **查询语言** | HQL  | SQL |  \n",
    "| **数据存储** | HDFS  | Local FS |\n",
    "| **执行引擎** | MR、Tez、Spark  | Excutor |\n",
    "| **执行延迟** | 高  | 低 |\n",
    "| **处理数据规模** | 大  | 小 |\n",
    "| **常见操作** | 导入数据、查询  | 增删改查 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5f7d9",
   "metadata": {},
   "source": [
    "# 7 什么是元数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa4e0c0",
   "metadata": {},
   "source": [
    "- 元数据（Metadata）\n",
    "    - 元数据（Metadata），又称中介数据、中继数据，为<font color=\"FF2121\">**描述数据的数据**</font>（data about data），主要是描述数据属性（property）的信息，用来支持如指示存储位置、历史数据、资源查找、文件记录等功能。\n",
    "- Hive Metadata\n",
    "    - Hive Metadata即Hive的**元数据**。\n",
    "    - 包含用Hive创建的database、table、表的位置、类型、属性、字段顺序类型等元信息。\n",
    "    - <font color=#E36C07>元数据存储在关系型数据库中</font>。如Hive内置的derby、或者第三方如MySQL.\n",
    "- Hive Metastore\n",
    "    - Metastore即<font color=\"FF2121\">**元数据服务**</font>。Metastore服务的作用是<font color=\"FF2121\">管理metadata元数据</font>，对外暴露服务地址，让各种客户端通过连接metastore服务，由metastore再去连接MySQL数据库来存取元数据。\n",
    "    - 有了metastore服务，就可以有多个客户端同时连接，而且这些客户端不需要知道MySQL数据库的用户名和密码，只需要连接metastore 服务即可。某种程度上也保证了hive元数据的安全。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6fab58",
   "metadata": {},
   "source": [
    "# 8 Metastore配置方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e998df6",
   "metadata": {},
   "source": [
    "## 8.1 概述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac965ae7",
   "metadata": {},
   "source": [
    "- metastore服务配置有3中模式\n",
    "    - 内嵌模式\n",
    "    - 本地模式\n",
    "    - 远程模式\n",
    "- 区分3中配置方式的关键是弄清楚两个问题：\n",
    "    - Metastore服务是否需要单独配置、单独启动？\n",
    "    - Metastore是存储在内置的derby中，还是第三方RDBMS，比如MySQL？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22f87e",
   "metadata": {},
   "source": [
    "| |  **内嵌模式**   | **本地模式**  | **远程模式**  |\n",
    "|  :----:  |  :----:  | :----:  |:----:  |\n",
    "| **Metastore单独配置、启动** | 否  | 否 | 是 |\n",
    "| **Metastore存储介质** | Derby | Mysql | Mysql | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e38d398",
   "metadata": {},
   "source": [
    "## 8.2 内嵌模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3fada",
   "metadata": {},
   "source": [
    "- <font color=\"FF2121\">**内嵌模式**</font>（Embedded Metastore）是Metastore默认部署模式。\n",
    "- 此种模式下，元数据存储在<font color=#E36C07>内置的Derby数据库</font>，并且Derby数据库和Metastore服务都嵌入在主HiveServer进程中，当启动HiveServer进程时，Derby和Metastore都会启动，<font color=#E36C07>不需要额外起Metastore服务</font>。\n",
    "- 但是一次只能支持一个活动用户，适用于测试体验，不适用于生产环境。\n",
    "<br>\n",
    "\n",
    "**Hive Service JVM： Hive Driver → Metastore → Derby**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231cd63c",
   "metadata": {},
   "source": [
    "# 8.3 本地模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4de4e",
   "metadata": {},
   "source": [
    "- <font color=\"FF2121\">**本地模式**</font>（Local Metastore）下，<font color=#E36C07>Metastore服务与主HiveServer进程在同一进程中运行</font>，但是存储元数据的数据库在单独的进程中运行，并且可以在单独的主机上。Metastore服务将通过JDBC与Metastore数据库进行通信。\n",
    "- <font color=#E36C07>本地模式采用外部数据库来存储元数据</font>，推荐使用MySQL。\n",
    "- hive根据hive.metastore.uris参数值来判断，如果为空，则为本地模式。\n",
    "- 缺点是：每启动一次hive服务，都内置启动了一个Metastore。\n",
    "<br>\n",
    "\n",
    "**Hive Service JVM： Hive Driver → Metastore↘ <br> Hive Service JVM： Hive Driver → Metastore↗\n",
    " MySql**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533ee32",
   "metadata": {},
   "source": [
    "# 8.4 远程模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22b273",
   "metadata": {},
   "source": [
    "- <font color=\"FF2121\">**远程模式**</font>（Remote Metastore）下，<font color=#E36C07>Metastore服务在其自己的单独JVM上运行，而不在HiveServer的JVM中运行</font>，如果其他进程希望与与Metastore服务器通信，则可以使用Thrift Network API进行通信。\n",
    "- 远程模式下，需要配置hive.metastore.uris参数来指定Metastore服务运行的机器ip和端口，并且<font color=#E36C07>需要单独手动启动Metastore服务</font>，元数据也采用外部数据库来存储元数据，推荐使用MySQL。\n",
    "- 在生产环境中，建议用远程模式来配置Hive Metastore。在这种情况下，其他依赖hive的软件都可以通过Metastore访问hive。由于还可以完全屏蔽数据库层，因此这也带来了更好的可管理性/安全性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d68bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
