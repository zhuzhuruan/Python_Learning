{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337f0671",
   "metadata": {},
   "source": [
    "# 1 - 网络连接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5818a8",
   "metadata": {},
   "source": [
    "理论上，网络数据采集是一种通过多种手段收集网络数据的方式，不光是通过与API交互（或者直接与浏览器交互）的方式。最常用的方法是写一个自动化程序向网络服务器请求数据（通常是用HTML表单或其他网页文件），然后对数据进行解析，提取需要的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3521c9d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "html = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b6a4d",
   "metadata": {},
   "source": [
    "这将会输出http://pythonscraping.com/pages/page1.html 这个网页的全部HTML代码。更准确地说，这会输出在域名为http://pythonscraping.com 的服务器上<网络应用根地址>/pages文件夹里的HTML文件page1.html的源代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4fa44",
   "metadata": {},
   "source": [
    "# 2 - BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01264d25",
   "metadata": {},
   "source": [
    "BeautifulSoup通过定位HTML标签来格式化和组织复杂的网络信息，用简单易用的Python对象为我们展现XML结构信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ea1f7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "bs0bj = BeautifulSoup(html.read())\n",
    "# 下面的函数调用都可以产生相同的效果\n",
    "print(bs0bj)\n",
    "print(bs0bj.h1)\n",
    "print(bs0bj.html.h1)\n",
    "print(bs0bj.body.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fa2fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "print(bs0bj.html.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec2662",
   "metadata": {},
   "source": [
    "# 3 - 可靠的网络连接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc2273f",
   "metadata": {},
   "source": [
    "html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534892b",
   "metadata": {},
   "source": [
    "这行代码主要可能会发生两种异常：\n",
    "- 网页在服务器上不存在（或者获取页面的时候出现错误）\n",
    "- 服务器不存在"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee52006",
   "metadata": {},
   "source": [
    "第一种异常发生时，程序会返回HTTP错误。HTTP错误可能是“404 Page Not Found”“500Internal Server Error”等。所有类似情形，urlopen函数都会抛出“HTTPError”异常。我们可以用下面的方式处理这种异常："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2aafc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "except HTTPError as e:\n",
    "    # 返回空值，中断程序，或者执行另一个方案\n",
    "    print(e)\n",
    "else:\n",
    "    # 程序继续，如果已经捕获了异常，则不执行这一段 \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a63a722",
   "metadata": {},
   "source": [
    "如果服务器不存在（就是说链接http://www.pythonscraping.com/ 打不开，或者是URL链接写错了），urlopen会返回一个None对象。这个对象与其他编程语言中的null类似。我们可以增加一个判断语句检测返回的html是不是None："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696353e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if html is None:\n",
    "    print(\"URL is not Found\")\n",
    "else:\n",
    "    # 程序继续"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f76a723",
   "metadata": {},
   "source": [
    "当然，即使网页已经从服务器成功获取，如果网页上的内容并非完全是我们期望的那样，仍然可能会出现异常。每当你调用BeautifulSoup对象里的一个标签时，增加一个检查条件保证标签确实存在是很聪明的做法。如果你想要调用的标签不存在，BeautifulSoup就会返回None对象。不过，如果再调用这个None对象下面的子标签，就会发生AttributeError错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04636cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(bs0bj.nonExistsTag)\n",
    "print(bs0bj.nonExistsTag.sometag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe255d",
   "metadata": {},
   "source": [
    "那么我们怎么才能避免这两种情形的异常呢？最简单的方式就是对两种情形进行检查："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    badcontent = bs0bj.nonExistsTag.anothertag\n",
    "except AttributeError as e:\n",
    "    print(\"Tag was not found\")\n",
    "else:\n",
    "    if badcontent == None:\n",
    "        print(\"Tag was not found\")\n",
    "    else:\n",
    "        print(badcontent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e304e96f",
   "metadata": {},
   "source": [
    "组织上面的检查异常的代码，下面是完整的写法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45ae45e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bs0bj = BeautifulSoup(html.read())\n",
    "        title = bs0bj.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "if title == None:\n",
    "    print(\"Title could not be Found\")\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa77491",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc2167a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
